Challenge scenario
You are starting your career as a junior cloud architect. In this role, you have been assigned to work on a team project that requires you to use the Cloud Natural Language API and Cloud Speech API services in Google Cloud.
Your challenge
For this challenge, you are asked to analyze some text and speech using the Cloud Natural Language API and Cloud Speech APIs, respectively. You also need to perform sentiment analysis on a text document using Python.
You need to:
Create an API key
Make an entity analysis request and call the Natural Language API
Create a speech analysis request and call the Speech API
Analyze sentiment with the Natural Language API
For this challenge lab, a virtual machine (VM) instance named Instance name has been configured for you to complete the tasks.
Each task is described in detail below, good luck!



###
Task 1. Create an API key
For this task, you need to create an API key to use in this and other tasks when sending a request to the Natural Language API.
Save the API key to use in other tasks.

***
Navigation menu > APIs & Services > Credentials.
Click Create credentials and select API key.
Copy the generated API key and click Close.

Navigation menu > Compute Engine. 
Click on the SSH button. 
In the command line, enter in the following, replacing <YOUR_API_KEY> with the key you just copied:
export API_KEY=AIzaSyD99wESybtsFnv5o5-9Po_v5cbBRp_0k3Q
***



###
Task 2. Make an entity analysis request and call the Natural Language API
connect to the instance Instance name provisioned for you via SSH.
create a JSON file named nl_request.json which you will pass to the Natural Language API for analysis. You can add the following code to your JSON file to analyze text about the city of Boston or, alternatively, add text of your own choosing to the content object to perform entity analysis on that instead.
{
  "document":{
    "type":"PLAIN_TEXT",
    "content":"With approximately 8.2 million people residing in Boston, the capital city of Massachusetts is one of the largest in the United States."
  },
  "encodingType":"UTF8"
}

You can now pass your request body, along with the API key environment variable you saved earlier, to the Natural Language API using the curl command or analyze the text using gcloud ML commands.
Save the response in a file called nl_response.json.

***
nano nl_request.json

{
  "document":{
    "type":"PLAIN_TEXT",
    "content":"With approximately 8.2 million people residing in Boston, the capital city of Massachusetts is one of the largest in the United States."
  },
  "encodingType":"UTF8"
}

CTRL+X to exit nano, then Y to save the file, then ENTER

curl "https://language.googleapis.com/v1/documents:analyzeEntities?key=${API_KEY}" \
  -s -X POST -H "Content-Type: application/json" --data-binary @nl_request.json > nl_response.json

cat nl_response.json

***





###
Task 3. Create a speech analysis request and call the Speech API
Note: For this task, you will use a pre-recorded file that's available on Cloud Storage: gs://cloud-samples-tests/speech/brooklyn.flac. Listen to the audio file before sending it to the Speech API.
Create another JSON file, named speech_request.json for this task, and add the content using the URI value of the sample audio file.
{
  "config": {
      "encoding":"FLAC",
      "languageCode": "en-US"
  },
  "audio": {
      "uri":"Pass the API the uri of the audio file in Cloud Storage"
  }
}

You can now pass your request body, along with the API key environment variable that you saved earlier, to the Natural Language API using the curl command or analyze the speech using gcloud ML commands.
Save the response in a file named speech_response.json.

***
nano speech_request.json

{
  "config": {
      "encoding":"FLAC",
      "languageCode": "en-US"
  },
  "audio": {
      "uri":"gs://cloud-samples-tests/speech/brooklyn.flac"
  }
}


CTRL+X to exit nano, then Y to save the file, then ENTER

curl -s -X POST -H "Content-Type: application/json" --data-binary @speech_request.json \
"https://speech.googleapis.com/v1/speech:recognize?key=${API_KEY}" > speech_response.json

cat speech_response.json
***




###
Task 4. Analyze sentiment with the Natural Language API
For this task, you need to analyze text sentiment using the Google Cloud Natural Language API, which attempts to determine the overall attitude (positive or negative) of a content sample such as a movie review. In the Instance name instance, a simple Python application code file called sentiment_analysis.py has already been configured and created for you. To perform your analysis, you'll test it on a set of (fictitious or fake) movie reviews for the 1982 sci-fi action film, Blade Runner, directed by Ridley Scott.
To use the Natural Language API to perform sentiment analysis, you need to access the service by calling the analyze_sentiment method of the LanguageServiceClient instance.
You need to edit the method def analyze(movie_review_filename): in the file sentiment_analysis.py and complete the method using Python code that performs the following actions:
Instantiate a LanguageServiceClient instance as the client.
Read the filename containing the text data into a variable.
Instantiate a Document object with the contents of the file.
Call the client's analyze_sentiment method.
Download the fictitious movie review samples from Google Cloud Storage: gs://cloud-samples-tests/natural-language/sentiment-samples.tgz .
Unzip the sample files and run the sentiment analysis on one of the files, bladerunner-pos.txt, using the relevant Python command.

***
cat > sentiment_analysis.py <<EOF

import argparse

from google.cloud import language_v1

def print_result(annotations):
    score = annotations.document_sentiment.score
    magnitude = annotations.document_sentiment.magnitude

    for index, sentence in enumerate(annotations.sentences):
        sentence_sentiment = sentence.sentiment.score
        print(
            f"Sentence {index} has a sentiment score of {sentence_sentiment}"
        )

    print(
        f"Overall Sentiment: score of {score} with magnitude of {magnitude}"
    )
    return 0


def analyze(movie_review_filename):
    """Run a sentiment analysis request on text within a passed filename."""
    client = language_v1.LanguageServiceClient()

    with open(movie_review_filename) as review_file:
        # Instantiates a plain text document.
        content = review_file.read()

    document = language_v1.Document(
        content=content, type_=language_v1.Document.Type.PLAIN_TEXT
    )
    annotations = client.analyze_sentiment(request={"document": document})

    # Print the results
    print_result(annotations)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "movie_review_filename",
        help="The filename of the movie review you'd like to analyze.",
    )
    args = parser.parse_args()

    analyze(args.movie_review_filename)

EOF



gsutil cp gs://cloud-samples-tests/natural-language/sentiment-samples.tgz .

gunzip sentiment-samples.tgz

tar -xvf sentiment-samples.tar

python3 sentiment_analysis.py reviews/bladerunner-pos.txt
***




Congratulations!

