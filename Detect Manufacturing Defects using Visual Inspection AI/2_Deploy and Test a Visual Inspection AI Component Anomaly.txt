2_Deploy and Test a Visual Inspection AI Component Anomaly Detection Solution

Visual Inspection AI Assembly Inspection inspects products when components come together during some stage of assembling a product. For such inspections, Visual Inspection AI can help you to ensure that components are in the correct location within the overall object, and that each component is not damaged or defective.
In this lab you will deploy and serve the exported Assembly Inspection solution using sample images.
Deploy a trained Assembly Inspection solution artifact.
Perform a batch prediction using an Assembly Inspection solution artifact.




Activate Cloud Shell
Click Activate Cloud Shell  at the top of the Google Cloud console.
	gcloud auth list
Click Authorize.
(Optional) You can list the project ID with this command:
	gcloud config list project




###
Task 1. Deploy the exported Assembly Inspection solution artifact

Run and test a CPU based solution artifact locally
Your first step is to connect to the Google Cloud VM. In Cloud Shell, enter the following command to connect to the VM:
		gcloud compute ssh lab-vm --zone us-central1-b

For any prompts, click Enter key to continue.

In the VM terminal, define a variable named DOCKER_TAG using the full image name of the docker container:
export DOCKER_TAG=gcr.io/ql-shared-resources-test/resistance_solution@sha256:d9095cbd6f7ca69b1a30c58c4272b68062d2004ed259ff0dcb9af0ceb92b393b

# Define variables for ports used by the solution artifact container:
export VISERVING_CPU_DOCKER_WITH_MODEL=${DOCKER_TAG}
export HTTP_PORT=8602
export LOCAL_METRIC_PORT=8603

# Pull the docker image from the Google Source Repository using the following command:
docker pull ${VISERVING_CPU_DOCKER_WITH_MODEL}

# Start the solution artifact locally using Docker in the VM:
docker run -v /secrets:/secrets --rm -d --name "test_cpu" \
--network="host" \
-p ${HTTP_PORT}:8602 \
-p ${LOCAL_METRIC_PORT}:8603 \
-t ${VISERVING_CPU_DOCKER_WITH_MODEL} \
--metric_project_id="${PROJECT_ID}" \
--use_default_credentials=false \
--service_account_credentials_json=/secrets/assembly-usage-reporter.json

# The reported usage metrics uploaded from the container include:
num_request_processed: the total number of processed requests.
prediction_latency: the prediction latency in one request.
average_prediction_latency: the average prediction latency.

#Confirm that the container is running:
docker container ls

You should see a container listed that has the image name for your solution artifact.

# Copy the file prediction_script.py to run predictions by calling the Visual Inspection AI rest APIs via the solution artifact container:
gsutil cp gs://cloud-training/gsp895/prediction_script.py .

# The code in this file is displayed below for your reference:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import base64
import json
import time
import re

from absl import app
from absl import flags
import numpy as np
import requests

flags.DEFINE_string('hostname', 'http://localhost', 'The hostname for serving.')
flags.DEFINE_string('input_image_file', None, 'The input image file name.')
flags.DEFINE_string('output_result_file', None, 'The prediction output file name.')
flags.DEFINE_integer('port', None, 'The port of rest api.')
flags.DEFINE_integer('num_of_requests', 1, 'The number of requests to send.')

FLAGS = flags.FLAGS

def create_request_body(input_image_file):
    """Creates the request body to perform api calls.

    Args:
    input_image_file: String, the input image file name.

    Returns:
    A json format string of the request body. The format is like below:
        {"image_bytes":}
    """

    with open(input_image_file, 'rb') as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')

    request_body = {'image_bytes': str(encoded_string)}

    return json.dumps(request_body)


def predict(hostname, input_image_file, port):
    """Predict results on the input image using services at the given port.

    Args:
    hostname: String, the host name for the serving.
    input_image_file: String, the input image file name.
    port: Integer, the port that runs the rest api service.

    Returns:
    The predicted results in json format. 
    """
    url = hostname + ':' + str(port) + '/v1beta1/visualInspection:predict'
    request_body = create_request_body(input_image_file)
    response = requests.post(url, data=request_body)
    return response.json()

def compute_latency_percentile(hostname, input_image_file, port,
                             num_of_requests):
    """Computes latency percentiles of server's prediction endpoint.

    Args:
    hostname: String, the host name for the serving.
    input_image_file: String, the input image file name.
    port: Integer, the port that runs the rest api service.
    num_of_requests: The number of requests to send.

    Returns:
    The dictionary of latency percentiles of 75%, 90%, 95%, 99%.
    """
    latency_list = []

    for _ in range(num_of_requests):
        response = predict(hostname, input_image_file, port)
        latency_in_ms = float(response['predictionLatency'][:-1])
        latency_list.append(latency_in_ms)

    latency_percentile = {}
    percentiles = [75, 90, 95, 99]
    for percentile in percentiles:
        latency_percentile[percentile] = np.percentile(latency_list, percentile)

    return latency_percentile


def main(_):
    if FLAGS.num_of_requests > 1:
        latency_percentile = compute_latency_percentile(FLAGS.hostname,
                                                        FLAGS.input_image_file,
                                                        FLAGS.port,
                                                        FLAGS.num_of_requests)
        print(latency_percentile)
        with open(FLAGS.output_result_file, 'w+') as latency_result:
            latency_result.write(json.dumps(latency_percentile))
    else:
        start = time.time()
        results = predict(FLAGS.hostname, FLAGS.input_image_file, FLAGS.port)
        end = time.time()
        print('Processed image {} in {}s.'.format(FLAGS.input_image_file, end - start))
        print(json.dumps(results, indent=2))
        with open(FLAGS.output_result_file, 'w+') as prediction_result:
            prediction_result.write(json.dumps(results, indent=2))


if __name__ == '__main__':
    flags.mark_flag_as_required('input_image_file')
    flags.mark_flag_as_required('port')
    flags.mark_flag_as_required('output_result_file')
    app.run(main)



Deploy the exported Assembly Inspection solution artifact






### 
Task 2. Serve the exported Assembly Inspection solution artifact

# Identifying a defective component
# In the VM terminal, run the commands below to copy training images to your Cloud Storage bucket, followed by copying a defective sample image to the VM:
export PROJECT_ID=$(gcloud config get-value core/project)
 gsutil mb gs://${PROJECT_ID}
 gsutil -m cp gs://cloud-training/gsp895/pcb_images/*.png \
 gs://${PROJECT_ID}/demo_pcb_images/
 gsutil cp gs://${PROJECT_ID}/demo_pcb_images/image_275_cx98_cy16_r-5.png .

# Find a defective component from the cloud storage bucket. In cloud console, go to Navigation menu () > Cloud Storage > Bucket.
# In the Cloud Storage Browser, navigate to the bucket named Bucket Name > demo_pcb_images.
# Now find and click on the image named image_275_cx98_cy16_r-5.png from the list of the images. You might have to scroll through the list to find this image.

This is a defective component that has a blue rectangle masking the resistor.

# In the terminal, run the following command to send the selected image as a request to the solution artifact container:
python3 ./prediction_script.py --input_image_file=./image_275_cx98_cy16_r-5.png  --port=8602 --output_result_file=def_prediction_result.json

# This will print out the JSON result data returned by your Visual Inspection AI model. 

# If you look at the annotation results you can see that Visual Inspection AI has assigned a relatively high confidence score (model defect score) of 0.652963758 for one of the components, parentAnnotationId": "localAnnotations/1000000" indicating that it is probably defective.
The script also stores the prediction result in a file named def_prediction_result.json that is created and saved in the HOME directory of the VM. This file is passed to the script using the flag --output_result_file.
...
        "annotations": [
          {
            "name": "localAnnotations/1000000",
            "annotationSpecId": "9163696043257233408",
            "annotationSetId": "1247523485060694016",
            "polygon": {
              "normalizedBoundingPoly": {
                "normalizedVertices": [
                  {
                    "x": 0.576829731,
                    "y": 0.649797797
                  },
                  {
                    "x": 0.671341896,
                    "y": 0.643206656
                  },
                  {
                    "x": 0.674117,
                    "y": 0.68300128
                  },
                  {
                    "x": 0.579604864,
                    "y": 0.689592421
                  }
                ]
              }
            },
            "source": {
              "type": "MACHINE_PRODUCED",
              "sourceModel": "projects/624839602356/locations/"REGION"
/solutions/1179028308696760320/modules/5557758599523991552/models/7472668050458673152"
            }
          },
...
        "annotations": [
          {
            "name": "localAnnotations/0",
            "annotationSpecId": "738868515330588672",
            "annotationSetId": "2346964744092516352",
            "parentAnnotationId": "localAnnotations/1000000",
            "classificationLabel": {
              "confidenceScore": 0.652963758
            },
            "source": {
              "type": "MACHINE_PRODUCED",
              "sourceModel": "projects/624839602356/locations/"REGION"/solutions/1179028308696760320/modules/5406888012007079936/models/1192398370090516480"
            }
          },
...

# Run the following command to send multiple requests to the running container:
python3 ./prediction_script.py --input_image_file=./image_275_cx98_cy16_r-5.png  --port=8602 --num_of_requests=10 --output_result_file=def_latency_result.json

The script calls the solution artifact 10 times and reports the distribution of the response latencies that are returned in the response each time the solution artifact processes an image. The script also stores the latency result in a file named def_latency_result.json that is created and saved in the HOME directory of the VM. This file is passed to the script using the flag --output_result_file.



Identifying a non-defective component
# In the VM terminal, run the commands below to copy a sample image with no defective components to the VM:
export PROJECT_ID=$(gcloud config get-value core/project)
gsutil cp gs://${PROJECT_ID}/demo_pcb_images/image_439_cx31_cy-35_r-4.png .

# Find a non-defective component from the cloud storage bucket.  go to Navigation menu () > Cloud Storage > Bucket. In the Cloud Storage Browser, navigate to the bucket named Bucket Name > demo_pcb_images.
# Now find and click on the image named image_439_cx31_cy-35_r-4.png from the list of the images. You might have to scroll through the list to find this image.

# This is a non-defective component that does not have any defects.
# In the terminal, run the following command to send the selected image as a request to the solution artifact container:
python3 ./prediction_script.py --input_image_file=./image_439_cx31_cy-35_r-4.png  --port=8602 --output_result_file=non_def_prediction_result.json

This will print out the JSON result data returned by your Visual Inspection AI model. You can inspect the annotation sets and annotations to see that this returns the same general data structures that were returned in the previous request. However this sample image is one of the non-defective images.
If you look at the annotation results you can see that Visual Inspection AI has assigned a relatively low confidence score (model defect score) of 0.0180127025 for one of the components, parentAnnotationId": "localAnnotations/1000000", indicating that it is probably non-defective.
The script also stores the prediction result in a file named non_def_prediction_result.json that is created and saved in the HOME directory of the VM. This file is passed to the script using the flag --output_result_file.
...
        "annotations": [
          {
            "name": "localAnnotations/1000000",
            "annotationSpecId": "9163696043257233408",
            "annotationSetId": "1247523485060694016",
            "polygon": {
              "normalizedBoundingPoly": {
                "normalizedVertices": [
                  {
                    "x": 0.506466269,
                    "y": 0.5975281
                  },
                  {
                    "x": 0.600979,
                    "y": 0.592597
                  },
                  {
                    "x": 0.603055239,
                    "y": 0.63239187
                  },
                  {
                    "x": 0.508542538,
                    "y": 0.637322962
                  }
                ]
              }
            },
            "source": {
              "type": "MACHINE_PRODUCED",
              "sourceModel": "projects/624839602356/locations/"REGION"/solutions/1179028308696760320/modules/5557758599523991552/models/7472668050458673152"
            }
          },
          {
            "name": "localAnnotations/1000001",
            "annotationSpecId": "9163696043257233408",
            "annotationSetId": "1247523485060694016",
            "polygon": {
              "normalizedBoundingPoly": {
                "normalizedVertices": [
                  {
                    "x": 0.590454638,
                    "y": 0.461126089
                  },
                  {
                    "x": 0.623952,
                    "y": 0.459378332
                  },
                  {
                    "x": 0.629263878,
                    "y": 0.56119138
                  },
                  {
                    "x": 0.595766544,
                    "y": 0.562939167
                  }
                ]
              }
            },
            "source": {
              "type": "MACHINE_PRODUCED",
              "sourceModel": "projects/624839602356/locations/"REGION"/solutions/1179028308696760320/modules/5557758599523991552/models/7472668050458673152"
            }
          }
        ]
      },
...
        "annotations": [
          {
            "name": "localAnnotations/0",
            "annotationSpecId": "738868515330588672",
            "annotationSetId": "2346964744092516352",
            "parentAnnotationId": "localAnnotations/1000000",
            "classificationLabel": {
              "confidenceScore": 0.0180127025
            },
            "source": {
              "type": "MACHINE_PRODUCED",
              "sourceModel": "projects/624839602356/locations/"REGION"/solutions/1179028308696760320/modules/5406888012007079936/models/1192398370090516480"
            }
          },
          {
            "name": "localAnnotations/1",
            "annotationSpecId": "738868515330588672",
            "annotationSetId": "2346964744092516352",
            "parentAnnotationId": "localAnnotations/1000001",
            "classificationLabel": {
              "confidenceScore": 0.0180627704
            },
            "source": {
              "type": "MACHINE_PRODUCED",
              "sourceModel": "projects/624839602356/locations/"REGION"/solutions/1179028308696760320/modules/5406888012007079936/models/1192398370090516480"
            }
          }
        ]
...

Run the following command to send multiple requests to the running container:
python3 ./prediction_script.py --input_image_file=./image_275_cx98_cy16_r-5.png  --port=8602 --num_of_requests=10 --output_result_file=non_def_latency_result.json

The script calls the solution artifact 10 times and again reports the distribution of the response latencies that are returned in the response each time the solution artifact processes an image. The script also stores the latency result in a file named non_def_latency_result.json that is created and saved in the HOME directory of the VM. This file is passed to the script using the flag --output_result_file.





Congratulations!
You've successfully deployed and served a Visual Inspection AI Component Anomaly Detection Solution.

