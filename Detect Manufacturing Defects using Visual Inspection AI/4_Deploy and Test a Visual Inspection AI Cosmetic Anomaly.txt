4_Deploy and Test a Visual Inspection AI Cosmetic Anomaly Detection Solution

Overview
Visual Inspection AI Cosmetic Inspection inspects products to detect and recognize defects such as dents, scratches, cracks, deformations, foreign materials, etc. on any kind of surface such as those shown in the following image.




###
Activate Cloud Shell
Click Activate Cloud Shell  at the top of the Google Cloud console.
	gcloud auth list
Click Authorize.
(Optional) You can list the project ID with this command:
	gcloud config list project



###
Task 1. Deploy the exported Cosmetic Inspection anomaly detection solution artifact
# Run and test a CPU-based solution artifact locally
# You need to map a local port to port 8602 for sending http requests, and another local port to port 8603 if you want to see the metrics logs locally.
# Your first step is to connect to the Google Cloud VM. In Cloud Shell, run the following command to connect to the VM:
gcloud compute ssh lab-vm --zone us-central1-b

# Type Y to continue.
# For any prompts, press Enter to continue.
# Define an environment variable to store the name of the Visual Inspection solution artifact Docker image that is stored in Container Registry.
# In the terminal, define a variable named DOCKER_TAG using the full image name of the docker container:
export DOCKER_TAG=gcr.io/ql-shared-resources-test/defect_solution@sha256:776fd8c65304ac017f5b9a986a1b8189695b7abbff6aa0e4ef693c46c7122f4c

# This is the Container Registry image ID of a Visual Inspection Cosmetic Inspection anomaly detection solution artifact that was trained using the Visual Inspection cosmetic defect demo dataset. This solution artifact will identify cosmetic defects in images.
# Define variables for ports used by the solution artifact container:
export VISERVING_CPU_DOCKER_WITH_MODEL=${DOCKER_TAG}
export HTTP_PORT=8602
export LOCAL_METRIC_PORT=8603

# Pull the docker image from the Google Source Repository using the following command:
docker pull ${VISERVING_CPU_DOCKER_WITH_MODEL}

# Start the solution artifact locally using Docker in the VM:
docker run -v /secrets:/secrets --rm -d --name "test_cpu" \
--network="host" \
-p ${HTTP_PORT}:8602 \
-p ${LOCAL_METRIC_PORT}:8603 \
-t ${VISERVING_CPU_DOCKER_WITH_MODEL} \
--metric_project_id="${PROJECT_ID}" \
--use_default_credentials=false \
--service_account_credentials_json=/secrets/assembly-usage-reporter.json

# The reported usage metrics uploaded from the container include:
num_request_processed: the total number of processed requests.
prediction_latency: the prediction latency in one request.
average_prediction_latency: the average prediction latency.
# Confirm that the container is running:
docker container ls


# Copy the file prediction_script.py to run predictions by calling Visual Inspection AI rest APIs via the solution artifact container:
gsutil cp gs://cloud-training/gsp895/prediction_script.py .

The code in this file is displayed below for your reference.
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import base64
import json
import time
import re

from absl import app
from absl import flags
import numpy as np
import requests

flags.DEFINE_string('hostname', 'http://localhost', 'The hostname for serving.')
flags.DEFINE_string('input_image_file', None, 'The input image file name.')
flags.DEFINE_string('output_result_file', None, 'The prediction output file name.')
flags.DEFINE_integer('port', None, 'The port of rest api.')
flags.DEFINE_integer('num_of_requests', 1, 'The number of requests to send.')

FLAGS = flags.FLAGS

def create_request_body(input_image_file):
    """Creates the request body to perform api calls.

    Args:
    input_image_file: String, the input image file name.

    Returns:
    A json format string of the request body. The format is like below:
        {"image_bytes":}
    """

    with open(input_image_file, 'rb') as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')

    request_body = {'image_bytes': str(encoded_string)}

    return json.dumps(request_body)


def predict(hostname, input_image_file, port):
    """Predict results on the input image using services at the given port.

    Args:
    hostname: String, the host name for the serving.
    input_image_file: String, the input image file name.
    port: Integer, the port that runs the rest api service.

    Returns:
    The predicted results in json format.
    """
    url = hostname + ':' + str(port) + '/v1beta1/visualInspection:predict'
    request_body = create_request_body(input_image_file)
    response = requests.post(url, data=request_body)
    return response.json()

def compute_latency_percentile(hostname, input_image_file, port,
                             num_of_requests):
    """Computes latency percentiles of server's prediction endpoint.

    Args:
    hostname: String, the host name for the serving.
    input_image_file: String, the input image file name.
    port: Integer, the port that runs the rest api service.
    num_of_requests: The number of requests to send.

    Returns:
    The dictionary of latency percentiles of 75%, 90%, 95%, 99%.
    """
    latency_list = []

    for _ in range(num_of_requests):
        response = predict(hostname, input_image_file, port)
        latency_in_ms = float(response['predictionLatency'][:-1])
        latency_list.append(latency_in_ms)

    latency_percentile = {}
    percentiles = [75, 90, 95, 99]
    for percentile in percentiles:
        latency_percentile[percentile] = np.percentile(latency_list, percentile)

    return latency_percentile


def main(_):
    if FLAGS.num_of_requests > 1:
        latency_percentile = compute_latency_percentile(FLAGS.hostname,
                                                        FLAGS.input_image_file,
                                                        FLAGS.port,
                                                        FLAGS.num_of_requests)
        print(latency_percentile)
        with open(FLAGS.output_result_file, 'w+') as latency_result:
            latency_result.write(json.dumps(latency_percentile))
    else:
        start = time.time()
        results = predict(FLAGS.hostname, FLAGS.input_image_file, FLAGS.port)
        end = time.time()
        print('Processed image {} in {}s.'.format(FLAGS.input_image_file, end - start))
        print(json.dumps(results, indent=2))
        with open(FLAGS.output_result_file, 'w+') as prediction_result:
            prediction_result.write(json.dumps(results, indent=2))


if __name__ == '__main__':
    flags.mark_flag_as_required('input_image_file')
    flags.mark_flag_as_required('port')
    flags.mark_flag_as_required('output_result_file')
    app.run(main)





###
Task 2. Serve the exported assembly inspection solution artifact
#  the VM terminal, run the commands below to copy training images to your Cloud Storage bucket, followed by copying a defective sample image to the VM:
export PROJECT_ID=$(gcloud config get-value core/project)
gsutil mb gs://${PROJECT_ID}
gsutil -m cp gs://cloud-training/gsp897/cosmetic-test-data/*.png \
gs://${PROJECT_ID}/cosmetic-test-data/
gsutil cp gs://${PROJECT_ID}/cosmetic-test-data/IMG_07703.png .

# Next, find a defective product from the cloud storage bucket. In the cloud console, go to Navigation menu > Cloud Storage > Buckets.
# In the Cloud Storage, navigate to the bucket named Bucket Name > cosmetic-test-data.
# Now find and click on the image named IMG_07703.png from the list of the images. You might have to scroll through the list to find this image.

# This is an image of a defective product that has a scratch on the surface.
# In the terminal, run the following command to send the selected image as a request to the solution artifact container:
python3 ./prediction_script.py --input_image_file=./IMG_07703.png  --port=8602 --output_result_file=def_prediction_result.json

#This will print out the JSON result data returned by your Visual Inspection AI model. You can inspect the annotation sets and annotations to see that this returns the same data structures that are returned when batch predictions are performed using the UI.
However this sample image is one of the images with a cosmetic defect. If you look at the annotation results, you can see that Visual Inspection AI has identified a scratch in this particular image.
The script also stores the prediction result in a file named def_prediction_result.json that is created and saved in the HOME directory of the VM. This file is passed to the script using the flag --output_result_file.
...
  "predictionResult": {
    "annotationsGroups": [
      {
...     "annotations": [
          {
            "name": "localAnnotations/1",
            "annotationSetId": "2435347886779662336",
            "mask": {
...
              "annotationSpecColors": [
                {
                  "annotationSpecId": "3513930310720946176",
                  "color": {
                    "red": 0.717647076,
                    "green": 0.615686297,
                    "blue": 0.356862754
                  },
                  "annotationSpecDisplayName": "scratch"
                }
              ]
...
  "predictionLatency": "1.299129679s"


# Run the following command to send multiple requests to the running container:
python3 ./prediction_script.py --input_image_file=./IMG_07703.png  --port=8602 --num_of_requests=10 --output_result_file=def_latency_result.json

The script calls the solution artifact 10 times and reports the distribution of the response latencies that are returned in the response each time the solution artifact processes an image. The script also stores the latency result in a file named def_latency_result.json that is created and saved in the HOME directory of the VM. This file is passed to the script using the flag --output_result_file.


###
Identifying a non-defective product
# In the VM terminal, run the commands below to copy a non-defective sample image to the VM:
export PROJECT_ID=$(gcloud config get-value core/project)
gsutil cp gs://${PROJECT_ID}/cosmetic-test-data/IMG_0769.png .

Next, find a non-defective product from the cloud storage bucket. If you are not in Cloud Storage browser, in cloud console, go to Navigation menu () > Cloud Storage > Buckets. In the Cloud Storage Browser, navigate to the bucket named Bucket Name > cosmetic-test-data.
Now find and click on the image named IMG_0769.png from the list of the images. You might have to scroll through the list to find this image.

This is a non-defective product that does not have any defects.
#In the terminal, run the following command to send the selected image as a request to the solution artifact container:
python3 ./prediction_script.py --input_image_file=./IMG_0769.png  --port=8602 --output_result_file=non_def_prediction_result.json

This will print out the JSON result data returned by your Visual Inspection AI model. You can inspect the annotation sets and annotations to see that this returns the same general data structures that were returned in the previous prediction.
However this sample image does not have any cosmetic defects present. If you look at the annotation results, you can see that Visual Inspection AI has not identified any region with either of the two defect types this model has been trained to identify, scratches or dents.
The script also stores the prediction result in a file named non_def_prediction_result.json that is created and saved in the HOME directory of the VM. This file is passed to the script using the flag --output_result_file.

{
  "predictionResult": {
    "annotationsGroups": [
      {
...
        "annotations": [
          {
            "name": "localAnnotations/1",
            "annotationSetId": "2435347886779662336",
            "mask": {
...
              "annotationSpecColors": [
                {
                  "annotationSpecId": "4043103266936979456",
                  "color": {},
                  "annotationSpecDisplayName": "none"
                }
              ]
...
  "predictionLatency": "0.414128490s"
}


# Run the following command in the VM terminal to send multiple requests to the running container:
python3 ./prediction_script.py --input_image_file=./IMG_0769.png  --port=8602 --num_of_requests=10 --output_result_file=non_def_latency_result.json


The script calls the solution artifact 10 times and reports the distribution of the response latencies that are returned in the response each time the solution artifact processes an image.
The script also stores the latency result in a file named non_def_latency_result.json that is created and saved in the HOME directory of the VM. This file is passed to the script using the flag --output_result_file.







Congratulations!
You've successfully deployed and served a Visual Inspection AI Component Inspection anomaly detection solution.

